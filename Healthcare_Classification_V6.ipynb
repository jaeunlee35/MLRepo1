{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Training Models\n",
      "Total parameter combinations: 243\n",
      "Training model 1/243 with parameters:\n",
      "Hidden sizes: [32, 16, 8], Optimizer: GradientDescentOptimizer, Learning rate: 0.01, Batch size: 16, Epochs: 100\n",
      "Epoch 1, Training Loss: 0.8863, Training Accuracy: 0.7781, Validation Loss: 0.8849, Validation Accuracy: 0.7793, Test Loss: 0.8852, Test Accuracy: 0.7793\n",
      "Epoch 10, Training Loss: 0.6535, Training Accuracy: 0.7781, Validation Loss: 0.6504, Validation Accuracy: 0.7793, Test Loss: 0.6507, Test Accuracy: 0.7793\n",
      "Epoch 20, Training Loss: 0.3544, Training Accuracy: 0.8507, Validation Loss: 0.3600, Validation Accuracy: 0.8545, Test Loss: 0.3679, Test Accuracy: 0.8451\n",
      "Epoch 30, Training Loss: 0.2568, Training Accuracy: 0.8944, Validation Loss: 0.2804, Validation Accuracy: 0.8967, Test Loss: 0.2892, Test Accuracy: 0.8920\n",
      "Epoch 40, Training Loss: 0.2244, Training Accuracy: 0.9059, Validation Loss: 0.2537, Validation Accuracy: 0.8920, Test Loss: 0.2630, Test Accuracy: 0.8897\n",
      "Epoch 50, Training Loss: 0.2059, Training Accuracy: 0.9119, Validation Loss: 0.2380, Validation Accuracy: 0.9014, Test Loss: 0.2501, Test Accuracy: 0.8967\n",
      "Epoch 60, Training Loss: 0.1918, Training Accuracy: 0.9159, Validation Loss: 0.2227, Validation Accuracy: 0.9014, Test Loss: 0.2416, Test Accuracy: 0.8991\n",
      "Epoch 70, Training Loss: 0.1797, Training Accuracy: 0.9233, Validation Loss: 0.2194, Validation Accuracy: 0.9061, Test Loss: 0.2405, Test Accuracy: 0.9014\n",
      "Epoch 80, Training Loss: 0.1688, Training Accuracy: 0.9280, Validation Loss: 0.2071, Validation Accuracy: 0.9061, Test Loss: 0.2337, Test Accuracy: 0.9108\n",
      "Epoch 90, Training Loss: 0.1589, Training Accuracy: 0.9348, Validation Loss: 0.2031, Validation Accuracy: 0.9155, Test Loss: 0.2350, Test Accuracy: 0.9178\n",
      "Epoch 100, Training Loss: 0.1498, Training Accuracy: 0.9354, Validation Loss: 0.1980, Validation Accuracy: 0.9249, Test Loss: 0.2389, Test Accuracy: 0.9249\n",
      "Optimizer: GradientDescentOptimizer, Learning rate: 0.01\n",
      "Hidden sizes: [32, 16, 8], Batch size: 16, Epochs: 100\n",
      "Training loss: 0.1498\n",
      "Validation loss: 0.1980\n",
      "Test loss: 0.2389\n",
      "Test Accuracy: 0.9249\n",
      "\n",
      "New best model found: Test Accuracy = 0.9249\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Training model 2/243 with parameters:\n",
      "Hidden sizes: [32, 16, 8], Optimizer: GradientDescentOptimizer, Learning rate: 0.01, Batch size: 16, Epochs: 200\n",
      "Epoch 1, Training Loss: 0.8929, Training Accuracy: 0.7781, Validation Loss: 0.8923, Validation Accuracy: 0.7793, Test Loss: 0.8922, Test Accuracy: 0.7793\n",
      "Epoch 10, Training Loss: 0.6770, Training Accuracy: 0.7781, Validation Loss: 0.6759, Validation Accuracy: 0.7793, Test Loss: 0.6751, Test Accuracy: 0.7793\n",
      "Epoch 20, Training Loss: 0.6636, Training Accuracy: 0.7781, Validation Loss: 0.6636, Validation Accuracy: 0.7793, Test Loss: 0.6623, Test Accuracy: 0.7793\n",
      "Epoch 30, Training Loss: 0.5728, Training Accuracy: 0.7781, Validation Loss: 0.5798, Validation Accuracy: 0.7793, Test Loss: 0.5779, Test Accuracy: 0.7793\n",
      "Epoch 40, Training Loss: 0.3763, Training Accuracy: 0.7828, Validation Loss: 0.3918, Validation Accuracy: 0.7840, Test Loss: 0.3973, Test Accuracy: 0.7864\n",
      "Epoch 50, Training Loss: 0.2651, Training Accuracy: 0.8944, Validation Loss: 0.2877, Validation Accuracy: 0.8873, Test Loss: 0.2973, Test Accuracy: 0.9061\n",
      "Epoch 60, Training Loss: 0.2203, Training Accuracy: 0.9092, Validation Loss: 0.2534, Validation Accuracy: 0.9061, Test Loss: 0.2582, Test Accuracy: 0.9038\n",
      "Epoch 70, Training Loss: 0.1970, Training Accuracy: 0.9193, Validation Loss: 0.2331, Validation Accuracy: 0.9155, Test Loss: 0.2388, Test Accuracy: 0.9038\n",
      "Epoch 80, Training Loss: 0.1860, Training Accuracy: 0.9233, Validation Loss: 0.2230, Validation Accuracy: 0.9061, Test Loss: 0.2334, Test Accuracy: 0.9108\n",
      "Epoch 90, Training Loss: 0.1779, Training Accuracy: 0.9206, Validation Loss: 0.2306, Validation Accuracy: 0.9014, Test Loss: 0.2367, Test Accuracy: 0.9202\n",
      "Epoch 100, Training Loss: 0.1675, Training Accuracy: 0.9348, Validation Loss: 0.2165, Validation Accuracy: 0.9155, Test Loss: 0.2284, Test Accuracy: 0.9249\n",
      "Epoch 110, Training Loss: 0.1616, Training Accuracy: 0.9314, Validation Loss: 0.2261, Validation Accuracy: 0.9014, Test Loss: 0.2368, Test Accuracy: 0.9249\n",
      "Epoch 120, Training Loss: 0.1542, Training Accuracy: 0.9381, Validation Loss: 0.2059, Validation Accuracy: 0.9108, Test Loss: 0.2322, Test Accuracy: 0.9296\n",
      "Epoch 130, Training Loss: 0.1458, Training Accuracy: 0.9375, Validation Loss: 0.2057, Validation Accuracy: 0.9108, Test Loss: 0.2378, Test Accuracy: 0.9296\n",
      "Epoch 140, Training Loss: 0.1409, Training Accuracy: 0.9435, Validation Loss: 0.1990, Validation Accuracy: 0.9108, Test Loss: 0.2339, Test Accuracy: 0.9178\n",
      "Epoch 150, Training Loss: 0.1276, Training Accuracy: 0.9475, Validation Loss: 0.2010, Validation Accuracy: 0.9108, Test Loss: 0.2350, Test Accuracy: 0.9249\n",
      "Epoch 160, Training Loss: 0.1325, Training Accuracy: 0.9395, Validation Loss: 0.2276, Validation Accuracy: 0.9296, Test Loss: 0.2593, Test Accuracy: 0.9319\n",
      "Epoch 170, Training Loss: 0.1182, Training Accuracy: 0.9509, Validation Loss: 0.1852, Validation Accuracy: 0.9249, Test Loss: 0.2543, Test Accuracy: 0.9202\n",
      "Epoch 180, Training Loss: 0.1046, Training Accuracy: 0.9597, Validation Loss: 0.2147, Validation Accuracy: 0.9061, Test Loss: 0.2618, Test Accuracy: 0.9178\n",
      "Epoch 190, Training Loss: 0.0967, Training Accuracy: 0.9623, Validation Loss: 0.2051, Validation Accuracy: 0.9202, Test Loss: 0.2636, Test Accuracy: 0.9249\n",
      "Epoch 200, Training Loss: 0.0893, Training Accuracy: 0.9670, Validation Loss: 0.2270, Validation Accuracy: 0.9155, Test Loss: 0.2827, Test Accuracy: 0.9178\n",
      "Optimizer: GradientDescentOptimizer, Learning rate: 0.01\n",
      "Hidden sizes: [32, 16, 8], Batch size: 16, Epochs: 200\n",
      "Training loss: 0.0893\n",
      "Validation loss: 0.2270\n",
      "Test loss: 0.2827\n",
      "Test Accuracy: 0.9178\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Training model 3/243 with parameters:\n",
      "Hidden sizes: [32, 16, 8], Optimizer: GradientDescentOptimizer, Learning rate: 0.01, Batch size: 16, Epochs: 300\n",
      "Epoch 1, Training Loss: 0.8896, Training Accuracy: 0.7781, Validation Loss: 0.8890, Validation Accuracy: 0.7793, Test Loss: 0.8887, Test Accuracy: 0.7793\n",
      "Epoch 10, Training Loss: 0.6720, Training Accuracy: 0.7781, Validation Loss: 0.6702, Validation Accuracy: 0.7793, Test Loss: 0.6693, Test Accuracy: 0.7793\n",
      "Epoch 20, Training Loss: 0.6159, Training Accuracy: 0.7781, Validation Loss: 0.6185, Validation Accuracy: 0.7793, Test Loss: 0.6170, Test Accuracy: 0.7793\n",
      "Epoch 30, Training Loss: 0.3764, Training Accuracy: 0.8352, Validation Loss: 0.3930, Validation Accuracy: 0.8498, Test Loss: 0.3969, Test Accuracy: 0.8498\n",
      "Epoch 40, Training Loss: 0.2993, Training Accuracy: 0.8453, Validation Loss: 0.3323, Validation Accuracy: 0.8357, Test Loss: 0.3310, Test Accuracy: 0.8545\n",
      "Epoch 50, Training Loss: 0.2411, Training Accuracy: 0.8924, Validation Loss: 0.2694, Validation Accuracy: 0.9061, Test Loss: 0.2830, Test Accuracy: 0.9014\n",
      "Epoch 60, Training Loss: 0.2047, Training Accuracy: 0.9126, Validation Loss: 0.2347, Validation Accuracy: 0.9155, Test Loss: 0.2559, Test Accuracy: 0.9108\n",
      "Epoch 70, Training Loss: 0.1863, Training Accuracy: 0.9220, Validation Loss: 0.2217, Validation Accuracy: 0.9155, Test Loss: 0.2401, Test Accuracy: 0.9202\n",
      "Epoch 80, Training Loss: 0.1746, Training Accuracy: 0.9260, Validation Loss: 0.2049, Validation Accuracy: 0.9202, Test Loss: 0.2335, Test Accuracy: 0.9202\n",
      "Epoch 90, Training Loss: 0.1675, Training Accuracy: 0.9368, Validation Loss: 0.2035, Validation Accuracy: 0.9202, Test Loss: 0.2368, Test Accuracy: 0.9178\n",
      "Epoch 100, Training Loss: 0.1546, Training Accuracy: 0.9321, Validation Loss: 0.2142, Validation Accuracy: 0.9155, Test Loss: 0.2462, Test Accuracy: 0.9272\n",
      "Epoch 110, Training Loss: 0.1469, Training Accuracy: 0.9348, Validation Loss: 0.2221, Validation Accuracy: 0.9202, Test Loss: 0.2588, Test Accuracy: 0.9202\n",
      "Epoch 120, Training Loss: 0.1356, Training Accuracy: 0.9428, Validation Loss: 0.2096, Validation Accuracy: 0.9155, Test Loss: 0.2652, Test Accuracy: 0.9225\n",
      "Epoch 130, Training Loss: 0.1255, Training Accuracy: 0.9509, Validation Loss: 0.2017, Validation Accuracy: 0.9155, Test Loss: 0.2717, Test Accuracy: 0.9272\n",
      "Epoch 140, Training Loss: 0.1242, Training Accuracy: 0.9428, Validation Loss: 0.2116, Validation Accuracy: 0.9343, Test Loss: 0.3071, Test Accuracy: 0.9225\n",
      "Epoch 150, Training Loss: 0.1111, Training Accuracy: 0.9529, Validation Loss: 0.2243, Validation Accuracy: 0.9343, Test Loss: 0.3053, Test Accuracy: 0.9202\n",
      "Epoch 160, Training Loss: 0.1244, Training Accuracy: 0.9482, Validation Loss: 0.2022, Validation Accuracy: 0.9155, Test Loss: 0.3321, Test Accuracy: 0.9108\n",
      "Epoch 170, Training Loss: 0.0993, Training Accuracy: 0.9583, Validation Loss: 0.1926, Validation Accuracy: 0.9343, Test Loss: 0.3484, Test Accuracy: 0.9155\n",
      "Epoch 180, Training Loss: 0.0959, Training Accuracy: 0.9563, Validation Loss: 0.2349, Validation Accuracy: 0.9249, Test Loss: 0.3441, Test Accuracy: 0.9085\n",
      "Epoch 190, Training Loss: 0.0954, Training Accuracy: 0.9603, Validation Loss: 0.2180, Validation Accuracy: 0.9155, Test Loss: 0.3600, Test Accuracy: 0.9155\n",
      "Epoch 200, Training Loss: 0.0786, Training Accuracy: 0.9691, Validation Loss: 0.2227, Validation Accuracy: 0.9390, Test Loss: 0.3522, Test Accuracy: 0.9225\n",
      "Epoch 210, Training Loss: 0.0691, Training Accuracy: 0.9744, Validation Loss: 0.2244, Validation Accuracy: 0.9437, Test Loss: 0.3703, Test Accuracy: 0.9272\n",
      "Epoch 220, Training Loss: 0.0685, Training Accuracy: 0.9724, Validation Loss: 0.2567, Validation Accuracy: 0.9296, Test Loss: 0.3766, Test Accuracy: 0.9272\n",
      "Epoch 230, Training Loss: 0.0613, Training Accuracy: 0.9792, Validation Loss: 0.2649, Validation Accuracy: 0.9437, Test Loss: 0.3850, Test Accuracy: 0.9366\n",
      "Epoch 240, Training Loss: 0.0637, Training Accuracy: 0.9765, Validation Loss: 0.2998, Validation Accuracy: 0.9390, Test Loss: 0.4139, Test Accuracy: 0.9272\n",
      "Epoch 250, Training Loss: 0.0671, Training Accuracy: 0.9711, Validation Loss: 0.2854, Validation Accuracy: 0.9155, Test Loss: 0.4653, Test Accuracy: 0.9249\n",
      "Epoch 260, Training Loss: 0.0582, Training Accuracy: 0.9738, Validation Loss: 0.3114, Validation Accuracy: 0.8967, Test Loss: 0.4253, Test Accuracy: 0.9296\n",
      "Epoch 270, Training Loss: 0.0464, Training Accuracy: 0.9825, Validation Loss: 0.3356, Validation Accuracy: 0.9249, Test Loss: 0.4747, Test Accuracy: 0.9272\n",
      "Epoch 280, Training Loss: 0.0531, Training Accuracy: 0.9818, Validation Loss: 0.4073, Validation Accuracy: 0.9061, Test Loss: 0.4491, Test Accuracy: 0.9178\n",
      "Epoch 290, Training Loss: 0.0592, Training Accuracy: 0.9731, Validation Loss: 0.3815, Validation Accuracy: 0.9155, Test Loss: 0.4786, Test Accuracy: 0.9131\n",
      "Epoch 300, Training Loss: 0.0612, Training Accuracy: 0.9697, Validation Loss: 0.3155, Validation Accuracy: 0.9155, Test Loss: 0.4965, Test Accuracy: 0.9225\n",
      "Optimizer: GradientDescentOptimizer, Learning rate: 0.01\n",
      "Hidden sizes: [32, 16, 8], Batch size: 16, Epochs: 300\n",
      "Training loss: 0.0612\n",
      "Validation loss: 0.3155\n",
      "Test loss: 0.4965\n",
      "Test Accuracy: 0.9225\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Training model 4/243 with parameters:\n",
      "Hidden sizes: [32, 16, 8], Optimizer: GradientDescentOptimizer, Learning rate: 0.01, Batch size: 32, Epochs: 100\n",
      "Epoch 1, Training Loss: 0.9675, Training Accuracy: 0.7781, Validation Loss: 0.9662, Validation Accuracy: 0.7793, Test Loss: 0.9663, Test Accuracy: 0.7793\n",
      "Epoch 10, Training Loss: 0.6852, Training Accuracy: 0.7781, Validation Loss: 0.6834, Validation Accuracy: 0.7793, Test Loss: 0.6826, Test Accuracy: 0.7793\n",
      "Epoch 20, Training Loss: 0.6343, Training Accuracy: 0.7781, Validation Loss: 0.6340, Validation Accuracy: 0.7793, Test Loss: 0.6345, Test Accuracy: 0.7793\n",
      "Epoch 30, Training Loss: 0.5288, Training Accuracy: 0.7781, Validation Loss: 0.5323, Validation Accuracy: 0.7793, Test Loss: 0.5371, Test Accuracy: 0.7793\n",
      "Epoch 40, Training Loss: 0.4114, Training Accuracy: 0.7781, Validation Loss: 0.4204, Validation Accuracy: 0.7793, Test Loss: 0.4303, Test Accuracy: 0.7793\n",
      "Epoch 50, Training Loss: 0.3373, Training Accuracy: 0.8413, Validation Loss: 0.3541, Validation Accuracy: 0.8357, Test Loss: 0.3638, Test Accuracy: 0.8474\n",
      "Epoch 60, Training Loss: 0.2989, Training Accuracy: 0.8736, Validation Loss: 0.3250, Validation Accuracy: 0.8873, Test Loss: 0.3266, Test Accuracy: 0.8826\n",
      "Epoch 70, Training Loss: 0.2662, Training Accuracy: 0.8890, Validation Loss: 0.2987, Validation Accuracy: 0.9061, Test Loss: 0.3000, Test Accuracy: 0.8920\n",
      "Epoch 80, Training Loss: 0.2397, Training Accuracy: 0.8924, Validation Loss: 0.2702, Validation Accuracy: 0.8967, Test Loss: 0.2735, Test Accuracy: 0.8967\n",
      "Epoch 90, Training Loss: 0.2201, Training Accuracy: 0.9018, Validation Loss: 0.2500, Validation Accuracy: 0.9108, Test Loss: 0.2562, Test Accuracy: 0.9014\n",
      "Epoch 100, Training Loss: 0.2057, Training Accuracy: 0.9106, Validation Loss: 0.2349, Validation Accuracy: 0.9108, Test Loss: 0.2434, Test Accuracy: 0.9085\n",
      "Optimizer: GradientDescentOptimizer, Learning rate: 0.01\n",
      "Hidden sizes: [32, 16, 8], Batch size: 32, Epochs: 100\n",
      "Training loss: 0.2057\n",
      "Validation loss: 0.2349\n",
      "Test loss: 0.2434\n",
      "Test Accuracy: 0.9085\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Training model 5/243 with parameters:\n",
      "Hidden sizes: [32, 16, 8], Optimizer: GradientDescentOptimizer, Learning rate: 0.01, Batch size: 32, Epochs: 200\n",
      "Epoch 1, Training Loss: 0.9748, Training Accuracy: 0.7781, Validation Loss: 0.9739, Validation Accuracy: 0.7793, Test Loss: 0.9748, Test Accuracy: 0.7793\n",
      "Epoch 10, Training Loss: 0.6870, Training Accuracy: 0.7781, Validation Loss: 0.6849, Validation Accuracy: 0.7793, Test Loss: 0.6855, Test Accuracy: 0.7793\n",
      "Epoch 20, Training Loss: 0.6480, Training Accuracy: 0.7781, Validation Loss: 0.6467, Validation Accuracy: 0.7793, Test Loss: 0.6460, Test Accuracy: 0.7793\n",
      "Epoch 30, Training Loss: 0.5529, Training Accuracy: 0.7781, Validation Loss: 0.5562, Validation Accuracy: 0.7793, Test Loss: 0.5528, Test Accuracy: 0.7793\n",
      "Epoch 40, Training Loss: 0.4053, Training Accuracy: 0.8346, Validation Loss: 0.4151, Validation Accuracy: 0.8451, Test Loss: 0.4165, Test Accuracy: 0.8521\n",
      "Epoch 50, Training Loss: 0.3345, Training Accuracy: 0.8413, Validation Loss: 0.3536, Validation Accuracy: 0.8451, Test Loss: 0.3575, Test Accuracy: 0.8498\n",
      "Epoch 60, Training Loss: 0.2898, Training Accuracy: 0.8803, Validation Loss: 0.3129, Validation Accuracy: 0.8920, Test Loss: 0.3206, Test Accuracy: 0.8920\n",
      "Epoch 70, Training Loss: 0.2566, Training Accuracy: 0.8870, Validation Loss: 0.2826, Validation Accuracy: 0.8920, Test Loss: 0.2854, Test Accuracy: 0.8873\n",
      "Epoch 80, Training Loss: 0.2352, Training Accuracy: 0.8890, Validation Loss: 0.2615, Validation Accuracy: 0.8920, Test Loss: 0.2654, Test Accuracy: 0.8897\n",
      "Epoch 90, Training Loss: 0.2198, Training Accuracy: 0.9005, Validation Loss: 0.2469, Validation Accuracy: 0.8920, Test Loss: 0.2541, Test Accuracy: 0.8944\n",
      "Epoch 100, Training Loss: 0.2074, Training Accuracy: 0.9092, Validation Loss: 0.2369, Validation Accuracy: 0.9108, Test Loss: 0.2435, Test Accuracy: 0.9038\n",
      "Epoch 110, Training Loss: 0.1974, Training Accuracy: 0.9139, Validation Loss: 0.2290, Validation Accuracy: 0.9108, Test Loss: 0.2355, Test Accuracy: 0.9131\n",
      "Epoch 120, Training Loss: 0.1910, Training Accuracy: 0.9166, Validation Loss: 0.2292, Validation Accuracy: 0.9014, Test Loss: 0.2347, Test Accuracy: 0.9178\n",
      "Epoch 130, Training Loss: 0.1834, Training Accuracy: 0.9220, Validation Loss: 0.2218, Validation Accuracy: 0.9014, Test Loss: 0.2284, Test Accuracy: 0.9131\n",
      "Epoch 140, Training Loss: 0.1785, Training Accuracy: 0.9220, Validation Loss: 0.2136, Validation Accuracy: 0.9061, Test Loss: 0.2230, Test Accuracy: 0.9178\n",
      "Epoch 150, Training Loss: 0.1728, Training Accuracy: 0.9260, Validation Loss: 0.2181, Validation Accuracy: 0.9061, Test Loss: 0.2233, Test Accuracy: 0.9202\n",
      "Epoch 160, Training Loss: 0.1682, Training Accuracy: 0.9267, Validation Loss: 0.2142, Validation Accuracy: 0.9108, Test Loss: 0.2256, Test Accuracy: 0.9225\n",
      "Epoch 170, Training Loss: 0.1641, Training Accuracy: 0.9274, Validation Loss: 0.2191, Validation Accuracy: 0.9108, Test Loss: 0.2270, Test Accuracy: 0.9249\n",
      "Epoch 180, Training Loss: 0.1600, Training Accuracy: 0.9301, Validation Loss: 0.2221, Validation Accuracy: 0.9108, Test Loss: 0.2278, Test Accuracy: 0.9272\n",
      "Epoch 190, Training Loss: 0.1559, Training Accuracy: 0.9328, Validation Loss: 0.2117, Validation Accuracy: 0.9155, Test Loss: 0.2257, Test Accuracy: 0.9296\n",
      "Epoch 200, Training Loss: 0.1516, Training Accuracy: 0.9354, Validation Loss: 0.2165, Validation Accuracy: 0.9108, Test Loss: 0.2270, Test Accuracy: 0.9319\n",
      "Optimizer: GradientDescentOptimizer, Learning rate: 0.01\n",
      "Hidden sizes: [32, 16, 8], Batch size: 32, Epochs: 200\n",
      "Training loss: 0.1516\n",
      "Validation loss: 0.2165\n",
      "Test loss: 0.2270\n",
      "Test Accuracy: 0.9319\n",
      "\n",
      "New best model found: Test Accuracy = 0.9319\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Training model 6/243 with parameters:\n",
      "Hidden sizes: [32, 16, 8], Optimizer: GradientDescentOptimizer, Learning rate: 0.01, Batch size: 32, Epochs: 300\n",
      "Epoch 1, Training Loss: 0.9786, Training Accuracy: 0.7781, Validation Loss: 0.9780, Validation Accuracy: 0.7793, Test Loss: 0.9785, Test Accuracy: 0.7793\n",
      "Epoch 10, Training Loss: 0.6932, Training Accuracy: 0.7781, Validation Loss: 0.6917, Validation Accuracy: 0.7793, Test Loss: 0.6915, Test Accuracy: 0.7793\n",
      "Epoch 20, Training Loss: 0.6653, Training Accuracy: 0.7781, Validation Loss: 0.6645, Validation Accuracy: 0.7793, Test Loss: 0.6637, Test Accuracy: 0.7793\n",
      "Epoch 30, Training Loss: 0.5959, Training Accuracy: 0.7781, Validation Loss: 0.6000, Validation Accuracy: 0.7793, Test Loss: 0.5964, Test Accuracy: 0.7793\n",
      "Epoch 40, Training Loss: 0.4396, Training Accuracy: 0.8292, Validation Loss: 0.4519, Validation Accuracy: 0.8263, Test Loss: 0.4508, Test Accuracy: 0.8357\n",
      "Epoch 50, Training Loss: 0.3612, Training Accuracy: 0.8709, Validation Loss: 0.3824, Validation Accuracy: 0.8873, Test Loss: 0.3795, Test Accuracy: 0.8638\n",
      "Epoch 60, Training Loss: 0.3154, Training Accuracy: 0.8796, Validation Loss: 0.3466, Validation Accuracy: 0.8967, Test Loss: 0.3369, Test Accuracy: 0.8779\n",
      "Epoch 70, Training Loss: 0.2793, Training Accuracy: 0.8863, Validation Loss: 0.3158, Validation Accuracy: 0.8920, Test Loss: 0.3015, Test Accuracy: 0.8897\n",
      "Epoch 80, Training Loss: 0.2543, Training Accuracy: 0.8917, Validation Loss: 0.2943, Validation Accuracy: 0.8920, Test Loss: 0.2772, Test Accuracy: 0.9014\n",
      "Epoch 90, Training Loss: 0.2362, Training Accuracy: 0.8978, Validation Loss: 0.2788, Validation Accuracy: 0.9061, Test Loss: 0.2632, Test Accuracy: 0.9085\n",
      "Epoch 100, Training Loss: 0.2225, Training Accuracy: 0.9032, Validation Loss: 0.2693, Validation Accuracy: 0.9155, Test Loss: 0.2538, Test Accuracy: 0.9061\n",
      "Epoch 110, Training Loss: 0.2110, Training Accuracy: 0.9085, Validation Loss: 0.2580, Validation Accuracy: 0.9108, Test Loss: 0.2430, Test Accuracy: 0.9085\n",
      "Epoch 120, Training Loss: 0.2019, Training Accuracy: 0.9146, Validation Loss: 0.2585, Validation Accuracy: 0.9108, Test Loss: 0.2409, Test Accuracy: 0.9202\n",
      "Epoch 130, Training Loss: 0.1925, Training Accuracy: 0.9200, Validation Loss: 0.2478, Validation Accuracy: 0.9108, Test Loss: 0.2336, Test Accuracy: 0.9178\n",
      "Epoch 140, Training Loss: 0.1862, Training Accuracy: 0.9220, Validation Loss: 0.2389, Validation Accuracy: 0.9108, Test Loss: 0.2289, Test Accuracy: 0.9249\n",
      "Epoch 150, Training Loss: 0.1784, Training Accuracy: 0.9233, Validation Loss: 0.2363, Validation Accuracy: 0.9108, Test Loss: 0.2300, Test Accuracy: 0.9272\n",
      "Epoch 160, Training Loss: 0.1718, Training Accuracy: 0.9240, Validation Loss: 0.2375, Validation Accuracy: 0.9108, Test Loss: 0.2291, Test Accuracy: 0.9296\n",
      "Epoch 170, Training Loss: 0.1661, Training Accuracy: 0.9267, Validation Loss: 0.2297, Validation Accuracy: 0.9155, Test Loss: 0.2281, Test Accuracy: 0.9249\n",
      "Epoch 180, Training Loss: 0.1608, Training Accuracy: 0.9307, Validation Loss: 0.2335, Validation Accuracy: 0.9155, Test Loss: 0.2299, Test Accuracy: 0.9249\n",
      "Epoch 190, Training Loss: 0.1622, Training Accuracy: 0.9328, Validation Loss: 0.2486, Validation Accuracy: 0.9061, Test Loss: 0.2409, Test Accuracy: 0.9225\n",
      "Epoch 200, Training Loss: 0.1513, Training Accuracy: 0.9334, Validation Loss: 0.2242, Validation Accuracy: 0.9155, Test Loss: 0.2303, Test Accuracy: 0.9296\n",
      "Epoch 210, Training Loss: 0.1470, Training Accuracy: 0.9354, Validation Loss: 0.2359, Validation Accuracy: 0.9108, Test Loss: 0.2347, Test Accuracy: 0.9272\n",
      "Epoch 220, Training Loss: 0.1413, Training Accuracy: 0.9368, Validation Loss: 0.2328, Validation Accuracy: 0.9108, Test Loss: 0.2353, Test Accuracy: 0.9272\n",
      "Epoch 230, Training Loss: 0.1360, Training Accuracy: 0.9375, Validation Loss: 0.2279, Validation Accuracy: 0.9155, Test Loss: 0.2367, Test Accuracy: 0.9296\n",
      "Epoch 240, Training Loss: 0.1350, Training Accuracy: 0.9428, Validation Loss: 0.2212, Validation Accuracy: 0.9108, Test Loss: 0.2408, Test Accuracy: 0.9249\n",
      "Epoch 250, Training Loss: 0.1278, Training Accuracy: 0.9415, Validation Loss: 0.2379, Validation Accuracy: 0.9155, Test Loss: 0.2480, Test Accuracy: 0.9296\n",
      "Epoch 260, Training Loss: 0.1242, Training Accuracy: 0.9462, Validation Loss: 0.2215, Validation Accuracy: 0.9155, Test Loss: 0.2497, Test Accuracy: 0.9249\n",
      "Epoch 270, Training Loss: 0.1233, Training Accuracy: 0.9462, Validation Loss: 0.2437, Validation Accuracy: 0.9014, Test Loss: 0.2694, Test Accuracy: 0.9249\n",
      "Epoch 280, Training Loss: 0.1158, Training Accuracy: 0.9536, Validation Loss: 0.2084, Validation Accuracy: 0.9155, Test Loss: 0.2620, Test Accuracy: 0.9225\n",
      "Epoch 290, Training Loss: 0.1325, Training Accuracy: 0.9455, Validation Loss: 0.2196, Validation Accuracy: 0.9108, Test Loss: 0.2844, Test Accuracy: 0.9178\n",
      "Epoch 300, Training Loss: 0.1025, Training Accuracy: 0.9583, Validation Loss: 0.2236, Validation Accuracy: 0.9202, Test Loss: 0.2763, Test Accuracy: 0.9319\n",
      "Optimizer: GradientDescentOptimizer, Learning rate: 0.01\n",
      "Hidden sizes: [32, 16, 8], Batch size: 32, Epochs: 300\n",
      "Training loss: 0.1025\n",
      "Validation loss: 0.2236\n",
      "Test loss: 0.2763\n",
      "Test Accuracy: 0.9319\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Training model 7/243 with parameters:\n",
      "Hidden sizes: [32, 16, 8], Optimizer: GradientDescentOptimizer, Learning rate: 0.01, Batch size: 64, Epochs: 100\n",
      "Epoch 1, Training Loss: 1.0295, Training Accuracy: 0.7781, Validation Loss: 1.0293, Validation Accuracy: 0.7793, Test Loss: 1.0292, Test Accuracy: 0.7793\n",
      "Epoch 10, Training Loss: 0.7477, Training Accuracy: 0.7781, Validation Loss: 0.7463, Validation Accuracy: 0.7793, Test Loss: 0.7462, Test Accuracy: 0.7793\n",
      "Epoch 20, Training Loss: 0.6892, Training Accuracy: 0.7781, Validation Loss: 0.6873, Validation Accuracy: 0.7793, Test Loss: 0.6872, Test Accuracy: 0.7793\n",
      "Epoch 30, Training Loss: 0.6744, Training Accuracy: 0.7781, Validation Loss: 0.6724, Validation Accuracy: 0.7793, Test Loss: 0.6724, Test Accuracy: 0.7793\n",
      "Epoch 40, Training Loss: 0.6654, Training Accuracy: 0.7781, Validation Loss: 0.6632, Validation Accuracy: 0.7793, Test Loss: 0.6634, Test Accuracy: 0.7793\n",
      "Epoch 50, Training Loss: 0.6526, Training Accuracy: 0.7781, Validation Loss: 0.6506, Validation Accuracy: 0.7793, Test Loss: 0.6507, Test Accuracy: 0.7793\n",
      "Epoch 60, Training Loss: 0.6296, Training Accuracy: 0.7781, Validation Loss: 0.6280, Validation Accuracy: 0.7793, Test Loss: 0.6278, Test Accuracy: 0.7793\n",
      "Epoch 70, Training Loss: 0.5919, Training Accuracy: 0.7781, Validation Loss: 0.5917, Validation Accuracy: 0.7793, Test Loss: 0.5914, Test Accuracy: 0.7793\n",
      "Epoch 80, Training Loss: 0.5397, Training Accuracy: 0.7781, Validation Loss: 0.5400, Validation Accuracy: 0.7793, Test Loss: 0.5413, Test Accuracy: 0.7793\n",
      "Epoch 90, Training Loss: 0.4843, Training Accuracy: 0.7781, Validation Loss: 0.4858, Validation Accuracy: 0.7793, Test Loss: 0.4902, Test Accuracy: 0.7793\n",
      "Epoch 100, Training Loss: 0.4331, Training Accuracy: 0.7781, Validation Loss: 0.4389, Validation Accuracy: 0.7793, Test Loss: 0.4445, Test Accuracy: 0.7793\n",
      "Optimizer: GradientDescentOptimizer, Learning rate: 0.01\n",
      "Hidden sizes: [32, 16, 8], Batch size: 64, Epochs: 100\n",
      "Training loss: 0.4331\n",
      "Validation loss: 0.4389\n",
      "Test loss: 0.4445\n",
      "Test Accuracy: 0.7793\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Training model 8/243 with parameters:\n",
      "Hidden sizes: [32, 16, 8], Optimizer: GradientDescentOptimizer, Learning rate: 0.01, Batch size: 64, Epochs: 200\n",
      "Epoch 1, Training Loss: 1.0324, Training Accuracy: 0.7781, Validation Loss: 1.0323, Validation Accuracy: 0.7793, Test Loss: 1.0324, Test Accuracy: 0.7793\n",
      "Epoch 10, Training Loss: 0.7508, Training Accuracy: 0.7781, Validation Loss: 0.7500, Validation Accuracy: 0.7793, Test Loss: 0.7496, Test Accuracy: 0.7793\n",
      "Epoch 20, Training Loss: 0.6895, Training Accuracy: 0.7781, Validation Loss: 0.6885, Validation Accuracy: 0.7793, Test Loss: 0.6877, Test Accuracy: 0.7793\n",
      "Epoch 30, Training Loss: 0.6743, Training Accuracy: 0.7781, Validation Loss: 0.6737, Validation Accuracy: 0.7793, Test Loss: 0.6725, Test Accuracy: 0.7793\n",
      "Epoch 40, Training Loss: 0.6654, Training Accuracy: 0.7781, Validation Loss: 0.6656, Validation Accuracy: 0.7793, Test Loss: 0.6637, Test Accuracy: 0.7793\n",
      "Epoch 50, Training Loss: 0.6527, Training Accuracy: 0.7781, Validation Loss: 0.6543, Validation Accuracy: 0.7793, Test Loss: 0.6515, Test Accuracy: 0.7793\n",
      "Epoch 60, Training Loss: 0.6268, Training Accuracy: 0.7781, Validation Loss: 0.6308, Validation Accuracy: 0.7793, Test Loss: 0.6268, Test Accuracy: 0.7793\n",
      "Epoch 70, Training Loss: 0.5812, Training Accuracy: 0.7781, Validation Loss: 0.5885, Validation Accuracy: 0.7793, Test Loss: 0.5832, Test Accuracy: 0.7793\n",
      "Epoch 80, Training Loss: 0.5234, Training Accuracy: 0.7781, Validation Loss: 0.5338, Validation Accuracy: 0.7793, Test Loss: 0.5279, Test Accuracy: 0.7793\n",
      "Epoch 90, Training Loss: 0.4646, Training Accuracy: 0.7781, Validation Loss: 0.4788, Validation Accuracy: 0.7793, Test Loss: 0.4723, Test Accuracy: 0.7793\n",
      "Epoch 100, Training Loss: 0.4169, Training Accuracy: 0.7781, Validation Loss: 0.4345, Validation Accuracy: 0.7793, Test Loss: 0.4270, Test Accuracy: 0.7793\n",
      "Epoch 110, Training Loss: 0.3783, Training Accuracy: 0.7922, Validation Loss: 0.3976, Validation Accuracy: 0.7840, Test Loss: 0.3912, Test Accuracy: 0.7887\n",
      "Epoch 120, Training Loss: 0.3483, Training Accuracy: 0.8447, Validation Loss: 0.3696, Validation Accuracy: 0.8404, Test Loss: 0.3637, Test Accuracy: 0.8521\n",
      "Epoch 130, Training Loss: 0.3257, Training Accuracy: 0.8440, Validation Loss: 0.3499, Validation Accuracy: 0.8357, Test Loss: 0.3433, Test Accuracy: 0.8521\n",
      "Epoch 140, Training Loss: 0.3059, Training Accuracy: 0.8487, Validation Loss: 0.3338, Validation Accuracy: 0.8404, Test Loss: 0.3283, Test Accuracy: 0.8592\n",
      "Epoch 150, Training Loss: 0.2889, Training Accuracy: 0.8796, Validation Loss: 0.3201, Validation Accuracy: 0.8779, Test Loss: 0.3136, Test Accuracy: 0.8897\n",
      "Epoch 160, Training Loss: 0.2727, Training Accuracy: 0.8911, Validation Loss: 0.3035, Validation Accuracy: 0.8826, Test Loss: 0.3012, Test Accuracy: 0.8944\n",
      "Epoch 170, Training Loss: 0.2580, Training Accuracy: 0.9032, Validation Loss: 0.2906, Validation Accuracy: 0.9061, Test Loss: 0.2906, Test Accuracy: 0.9038\n",
      "Epoch 180, Training Loss: 0.2448, Training Accuracy: 0.9059, Validation Loss: 0.2798, Validation Accuracy: 0.8967, Test Loss: 0.2806, Test Accuracy: 0.8991\n",
      "Epoch 190, Training Loss: 0.2331, Training Accuracy: 0.9132, Validation Loss: 0.2704, Validation Accuracy: 0.8967, Test Loss: 0.2723, Test Accuracy: 0.9014\n",
      "Epoch 200, Training Loss: 0.2232, Training Accuracy: 0.9146, Validation Loss: 0.2628, Validation Accuracy: 0.9014, Test Loss: 0.2658, Test Accuracy: 0.9038\n",
      "Optimizer: GradientDescentOptimizer, Learning rate: 0.01\n",
      "Hidden sizes: [32, 16, 8], Batch size: 64, Epochs: 200\n",
      "Training loss: 0.2232\n",
      "Validation loss: 0.2628\n",
      "Test loss: 0.2658\n",
      "Test Accuracy: 0.9038\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Training model 9/243 with parameters:\n",
      "Hidden sizes: [32, 16, 8], Optimizer: GradientDescentOptimizer, Learning rate: 0.01, Batch size: 64, Epochs: 300\n",
      "Epoch 1, Training Loss: 1.0330, Training Accuracy: 0.7781, Validation Loss: 1.0330, Validation Accuracy: 0.7793, Test Loss: 1.0329, Test Accuracy: 0.7793\n",
      "Epoch 10, Training Loss: 0.7549, Training Accuracy: 0.7781, Validation Loss: 0.7538, Validation Accuracy: 0.7793, Test Loss: 0.7536, Test Accuracy: 0.7793\n",
      "Epoch 20, Training Loss: 0.6924, Training Accuracy: 0.7781, Validation Loss: 0.6906, Validation Accuracy: 0.7793, Test Loss: 0.6907, Test Accuracy: 0.7793\n",
      "Epoch 30, Training Loss: 0.6765, Training Accuracy: 0.7781, Validation Loss: 0.6744, Validation Accuracy: 0.7793, Test Loss: 0.6746, Test Accuracy: 0.7793\n",
      "Epoch 40, Training Loss: 0.6691, Training Accuracy: 0.7781, Validation Loss: 0.6670, Validation Accuracy: 0.7793, Test Loss: 0.6673, Test Accuracy: 0.7793\n",
      "Epoch 50, Training Loss: 0.6610, Training Accuracy: 0.7781, Validation Loss: 0.6590, Validation Accuracy: 0.7793, Test Loss: 0.6595, Test Accuracy: 0.7793\n",
      "Epoch 60, Training Loss: 0.6469, Training Accuracy: 0.7781, Validation Loss: 0.6453, Validation Accuracy: 0.7793, Test Loss: 0.6458, Test Accuracy: 0.7793\n",
      "Epoch 70, Training Loss: 0.6161, Training Accuracy: 0.7781, Validation Loss: 0.6158, Validation Accuracy: 0.7793, Test Loss: 0.6160, Test Accuracy: 0.7793\n",
      "Epoch 80, Training Loss: 0.5387, Training Accuracy: 0.7781, Validation Loss: 0.5422, Validation Accuracy: 0.7793, Test Loss: 0.5422, Test Accuracy: 0.7793\n",
      "Epoch 90, Training Loss: 0.4208, Training Accuracy: 0.8225, Validation Loss: 0.4377, Validation Accuracy: 0.8263, Test Loss: 0.4329, Test Accuracy: 0.8239\n",
      "Epoch 100, Training Loss: 0.3584, Training Accuracy: 0.8662, Validation Loss: 0.3810, Validation Accuracy: 0.8732, Test Loss: 0.3759, Test Accuracy: 0.8592\n",
      "Epoch 110, Training Loss: 0.3234, Training Accuracy: 0.8776, Validation Loss: 0.3501, Validation Accuracy: 0.8873, Test Loss: 0.3440, Test Accuracy: 0.8803\n",
      "Epoch 120, Training Loss: 0.3001, Training Accuracy: 0.8796, Validation Loss: 0.3295, Validation Accuracy: 0.8967, Test Loss: 0.3229, Test Accuracy: 0.8826\n",
      "Epoch 130, Training Loss: 0.2824, Training Accuracy: 0.8843, Validation Loss: 0.3138, Validation Accuracy: 0.9014, Test Loss: 0.3066, Test Accuracy: 0.8967\n",
      "Epoch 140, Training Loss: 0.2676, Training Accuracy: 0.8816, Validation Loss: 0.2983, Validation Accuracy: 0.8920, Test Loss: 0.2925, Test Accuracy: 0.8920\n",
      "Epoch 150, Training Loss: 0.2556, Training Accuracy: 0.8830, Validation Loss: 0.2830, Validation Accuracy: 0.8967, Test Loss: 0.2799, Test Accuracy: 0.8991\n",
      "Epoch 160, Training Loss: 0.2451, Training Accuracy: 0.8897, Validation Loss: 0.2713, Validation Accuracy: 0.9061, Test Loss: 0.2710, Test Accuracy: 0.8920\n",
      "Epoch 170, Training Loss: 0.2357, Training Accuracy: 0.8911, Validation Loss: 0.2605, Validation Accuracy: 0.9014, Test Loss: 0.2624, Test Accuracy: 0.8944\n",
      "Epoch 180, Training Loss: 0.2281, Training Accuracy: 0.8978, Validation Loss: 0.2521, Validation Accuracy: 0.8967, Test Loss: 0.2556, Test Accuracy: 0.9061\n",
      "Epoch 190, Training Loss: 0.2218, Training Accuracy: 0.9005, Validation Loss: 0.2438, Validation Accuracy: 0.8967, Test Loss: 0.2486, Test Accuracy: 0.9085\n",
      "Epoch 200, Training Loss: 0.2159, Training Accuracy: 0.9018, Validation Loss: 0.2419, Validation Accuracy: 0.9061, Test Loss: 0.2461, Test Accuracy: 0.9131\n",
      "Epoch 210, Training Loss: 0.2109, Training Accuracy: 0.9038, Validation Loss: 0.2351, Validation Accuracy: 0.9061, Test Loss: 0.2399, Test Accuracy: 0.9178\n",
      "Epoch 220, Training Loss: 0.2065, Training Accuracy: 0.9072, Validation Loss: 0.2324, Validation Accuracy: 0.9108, Test Loss: 0.2374, Test Accuracy: 0.9202\n",
      "Epoch 230, Training Loss: 0.2029, Training Accuracy: 0.9119, Validation Loss: 0.2266, Validation Accuracy: 0.9108, Test Loss: 0.2339, Test Accuracy: 0.9131\n",
      "Epoch 240, Training Loss: 0.1990, Training Accuracy: 0.9112, Validation Loss: 0.2290, Validation Accuracy: 0.9014, Test Loss: 0.2359, Test Accuracy: 0.9225\n",
      "Epoch 250, Training Loss: 0.1952, Training Accuracy: 0.9139, Validation Loss: 0.2262, Validation Accuracy: 0.9061, Test Loss: 0.2333, Test Accuracy: 0.9202\n",
      "Epoch 260, Training Loss: 0.1913, Training Accuracy: 0.9186, Validation Loss: 0.2233, Validation Accuracy: 0.9108, Test Loss: 0.2308, Test Accuracy: 0.9225\n",
      "Epoch 270, Training Loss: 0.1893, Training Accuracy: 0.9186, Validation Loss: 0.2172, Validation Accuracy: 0.9202, Test Loss: 0.2281, Test Accuracy: 0.9202\n",
      "Epoch 280, Training Loss: 0.1852, Training Accuracy: 0.9200, Validation Loss: 0.2185, Validation Accuracy: 0.9155, Test Loss: 0.2267, Test Accuracy: 0.9249\n",
      "Epoch 290, Training Loss: 0.1828, Training Accuracy: 0.9200, Validation Loss: 0.2244, Validation Accuracy: 0.9108, Test Loss: 0.2309, Test Accuracy: 0.9296\n",
      "Epoch 300, Training Loss: 0.1797, Training Accuracy: 0.9200, Validation Loss: 0.2190, Validation Accuracy: 0.9108, Test Loss: 0.2294, Test Accuracy: 0.9296\n",
      "Optimizer: GradientDescentOptimizer, Learning rate: 0.01\n",
      "Hidden sizes: [32, 16, 8], Batch size: 64, Epochs: 300\n",
      "Training loss: 0.1797\n",
      "Validation loss: 0.2190\n",
      "Test loss: 0.2294\n",
      "Test Accuracy: 0.9296\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Training model 10/243 with parameters:\n",
      "Hidden sizes: [32, 16, 8], Optimizer: GradientDescentOptimizer, Learning rate: 0.001, Batch size: 16, Epochs: 100\n",
      "Epoch 1, Training Loss: 1.0734, Training Accuracy: 0.7787, Validation Loss: 1.0733, Validation Accuracy: 0.7793, Test Loss: 1.0729, Test Accuracy: 0.7793\n",
      "Epoch 10, Training Loss: 0.8938, Training Accuracy: 0.7781, Validation Loss: 0.8933, Validation Accuracy: 0.7793, Test Loss: 0.8929, Test Accuracy: 0.7793\n",
      "Epoch 20, Training Loss: 0.7896, Training Accuracy: 0.7781, Validation Loss: 0.7887, Validation Accuracy: 0.7793, Test Loss: 0.7881, Test Accuracy: 0.7793\n",
      "Epoch 30, Training Loss: 0.7366, Training Accuracy: 0.7781, Validation Loss: 0.7355, Validation Accuracy: 0.7793, Test Loss: 0.7346, Test Accuracy: 0.7793\n",
      "Epoch 40, Training Loss: 0.7086, Training Accuracy: 0.7781, Validation Loss: 0.7073, Validation Accuracy: 0.7793, Test Loss: 0.7064, Test Accuracy: 0.7793\n",
      "Epoch 50, Training Loss: 0.6932, Training Accuracy: 0.7781, Validation Loss: 0.6917, Validation Accuracy: 0.7793, Test Loss: 0.6907, Test Accuracy: 0.7793\n",
      "Epoch 60, Training Loss: 0.6843, Training Accuracy: 0.7781, Validation Loss: 0.6824, Validation Accuracy: 0.7793, Test Loss: 0.6814, Test Accuracy: 0.7793\n",
      "Epoch 70, Training Loss: 0.6786, Training Accuracy: 0.7781, Validation Loss: 0.6765, Validation Accuracy: 0.7793, Test Loss: 0.6755, Test Accuracy: 0.7793\n",
      "Epoch 80, Training Loss: 0.6747, Training Accuracy: 0.7781, Validation Loss: 0.6724, Validation Accuracy: 0.7793, Test Loss: 0.6714, Test Accuracy: 0.7793\n",
      "Epoch 90, Training Loss: 0.6717, Training Accuracy: 0.7781, Validation Loss: 0.6690, Validation Accuracy: 0.7793, Test Loss: 0.6682, Test Accuracy: 0.7793\n",
      "Epoch 100, Training Loss: 0.6691, Training Accuracy: 0.7781, Validation Loss: 0.6659, Validation Accuracy: 0.7793, Test Loss: 0.6654, Test Accuracy: 0.7793\n",
      "Optimizer: GradientDescentOptimizer, Learning rate: 0.001\n",
      "Hidden sizes: [32, 16, 8], Batch size: 16, Epochs: 100\n",
      "Training loss: 0.6691\n",
      "Validation loss: 0.6659\n",
      "Test loss: 0.6654\n",
      "Test Accuracy: 0.7793\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Training model 11/243 with parameters:\n",
      "Hidden sizes: [32, 16, 8], Optimizer: GradientDescentOptimizer, Learning rate: 0.001, Batch size: 16, Epochs: 200\n",
      "Epoch 1, Training Loss: 1.0644, Training Accuracy: 0.7781, Validation Loss: 1.0637, Validation Accuracy: 0.7793, Test Loss: 1.0656, Test Accuracy: 0.7793\n",
      "Epoch 10, Training Loss: 0.8780, Training Accuracy: 0.7781, Validation Loss: 0.8768, Validation Accuracy: 0.7793, Test Loss: 0.8791, Test Accuracy: 0.7793\n",
      "Epoch 20, Training Loss: 0.7681, Training Accuracy: 0.7781, Validation Loss: 0.7670, Validation Accuracy: 0.7793, Test Loss: 0.7691, Test Accuracy: 0.7793\n",
      "Epoch 30, Training Loss: 0.7138, Training Accuracy: 0.7781, Validation Loss: 0.7131, Validation Accuracy: 0.7793, Test Loss: 0.7147, Test Accuracy: 0.7793\n",
      "Epoch 40, Training Loss: 0.6857, Training Accuracy: 0.7781, Validation Loss: 0.6857, Validation Accuracy: 0.7793, Test Loss: 0.6867, Test Accuracy: 0.7793\n",
      "Epoch 50, Training Loss: 0.6685, Training Accuracy: 0.7781, Validation Loss: 0.6692, Validation Accuracy: 0.7793, Test Loss: 0.6698, Test Accuracy: 0.7793\n",
      "Epoch 60, Training Loss: 0.6548, Training Accuracy: 0.7781, Validation Loss: 0.6561, Validation Accuracy: 0.7793, Test Loss: 0.6564, Test Accuracy: 0.7793\n",
      "Epoch 70, Training Loss: 0.6415, Training Accuracy: 0.7781, Validation Loss: 0.6433, Validation Accuracy: 0.7793, Test Loss: 0.6438, Test Accuracy: 0.7793\n",
      "Epoch 80, Training Loss: 0.6260, Training Accuracy: 0.7781, Validation Loss: 0.6284, Validation Accuracy: 0.7793, Test Loss: 0.6294, Test Accuracy: 0.7793\n",
      "Epoch 90, Training Loss: 0.6060, Training Accuracy: 0.7781, Validation Loss: 0.6088, Validation Accuracy: 0.7793, Test Loss: 0.6110, Test Accuracy: 0.7793\n",
      "Epoch 100, Training Loss: 0.5817, Training Accuracy: 0.7781, Validation Loss: 0.5847, Validation Accuracy: 0.7793, Test Loss: 0.5887, Test Accuracy: 0.7793\n",
      "Epoch 110, Training Loss: 0.5558, Training Accuracy: 0.7781, Validation Loss: 0.5587, Validation Accuracy: 0.7793, Test Loss: 0.5652, Test Accuracy: 0.7793\n",
      "Epoch 120, Training Loss: 0.5302, Training Accuracy: 0.7781, Validation Loss: 0.5330, Validation Accuracy: 0.7793, Test Loss: 0.5419, Test Accuracy: 0.7793\n",
      "Epoch 130, Training Loss: 0.5062, Training Accuracy: 0.7781, Validation Loss: 0.5088, Validation Accuracy: 0.7793, Test Loss: 0.5196, Test Accuracy: 0.7793\n",
      "Epoch 140, Training Loss: 0.4841, Training Accuracy: 0.7781, Validation Loss: 0.4879, Validation Accuracy: 0.7793, Test Loss: 0.4992, Test Accuracy: 0.7793\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "\n",
    "########################\n",
    "# Data\n",
    "\n",
    "def load_csv(file_path):\n",
    "    # CSV 파일 로드\n",
    "    data = np.loadtxt(file_path, delimiter=',', skiprows=1)\n",
    "    \n",
    "    # 입력 변수와 목표 변수 분리 ('fetal_health'를 목표 변수로 설정)\n",
    "    x_data = data[:, :-1]  # 마지막 열 제외 (입력 변수)\n",
    "    y_data = data[:, -1].astype(int)  # 마지막 열 (목표 변수)\n",
    "    \n",
    "    # 목표 변수를 one-hot 인코딩으로 변환\n",
    "    y_data = tf.one_hot(y_data - 1, depth=3).eval(session=tf.Session())\n",
    "\n",
    "    return x_data, y_data\n",
    "\n",
    "def split_data(x_data, y_data):\n",
    "    # 데이터셋을 학습, 검증, 테스트로 나누기\n",
    "    # random_state는 Seed값으로 동일한 분할 결과를 얻기 위해 사용\n",
    "    # stratify는 클래스 비율 유지를 위해 사용\n",
    "    # 전체 데이터의 20%를 테스트 데이터로 사용\n",
    "    x_temp, x_test, y_temp, y_test = train_test_split(\n",
    "        x_data, y_data, test_size=0.2, random_state=42, stratify=y_data)\n",
    "    # 테스트 데이터를 제외한 나머지 데이터의 12.5%를 검증 데이터로 사용, 나머지를 학습 데이터로 사용\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        x_temp, y_temp, test_size=0.125, random_state=42, stratify=y_temp)\n",
    "\n",
    "    # 표준화 (스케일링)\n",
    "    sc = StandardScaler()\n",
    "    # 학습 데이터에 fit_transform을 사용하여 평균과 표준편차를 계산하고 데이터를 표준화\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    # 검증 및 테스트 데이터에는 학습 데이터의 평균과 표준편차를 사용하여 동일하게 표준화\n",
    "    x_test = sc.transform(x_test)\n",
    "    x_val = sc.transform(x_val)\n",
    "    \n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test\n",
    "\n",
    "########################\n",
    "# Learning\n",
    "\n",
    "def create_model(optimizer, input_num, hidden_sizes):\n",
    "    tf.reset_default_graph()  # 그래프 초기화\n",
    "    x = tf.placeholder(tf.float32, [None, input_num], name='x')  # 입력 데이터 플레이스홀더\n",
    "    y = tf.placeholder(tf.float32, [None, 3], name='y')  # 레이블 데이터 플레이스홀더 (3개의 클래스)\n",
    "\n",
    "    # 히든 레이어 생성\n",
    "    layer_input = x\n",
    "    layer_input_size = input_num\n",
    "    for idx, hidden_size in enumerate(hidden_sizes):\n",
    "        # 가중치 및 바이어스 초기화\n",
    "        # tf.random.normal - 정규 분포를 따르는 랜덤 값 생성, 가중치 초기화용\n",
    "        W_hidden = tf.Variable(tf.random.normal([layer_input_size, hidden_size], stddev=0.1), name=f'W_hidden_{idx+1}')\n",
    "        b_hidden = tf.Variable(tf.zeros([hidden_size]), name=f'b_hidden_{idx+1}')\n",
    "        # 레이어 출력 계산\n",
    "        layer_output = tf.nn.relu(tf.matmul(layer_input, W_hidden) + b_hidden, name=f'relu_{idx+1}')\n",
    "        # 다음 레이어를 위해 업데이트\n",
    "        layer_input = layer_output\n",
    "        layer_input_size = hidden_size\n",
    "\n",
    "    # 출력 레이어 (3개의 클래스에 대한 확률)\n",
    "    W_output = tf.Variable(tf.random.normal([layer_input_size, 3], stddev=0.1), name='W_output')\n",
    "    b_output = tf.Variable(tf.zeros([3]), name='b_output')\n",
    "    logits = tf.matmul(layer_input, W_output) + b_output\n",
    "    prediction = tf.nn.softmax(logits, name='prediction')\n",
    "\n",
    "    # 손실 함수 (크로스 엔트로피) 및 최적화 방법 정의\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=logits), name='loss')\n",
    "    train_step = optimizer.minimize(loss, name='train_step')\n",
    "\n",
    "    # 정확도 계산\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "\n",
    "    return x, y, prediction, loss, train_step, accuracy\n",
    "\n",
    "# 모델 학습 및 평가 함수\n",
    "def execute_model(x, y, prediction, loss, train_step, accuracy, data, epochs, batch_size):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    test_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    x_train, x_val, x_test, y_train, y_val, y_test = data\n",
    "       \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())  # 변수 초기화\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            # 학습 데이터 셔플\n",
    "            permutation = np.random.permutation(len(x_train))\n",
    "            x_train_shuffled = x_train[permutation]\n",
    "            y_train_shuffled = y_train[permutation]\n",
    "\n",
    "            num_batches = (len(x_train) + batch_size - 1) // batch_size\n",
    "            for i in range(num_batches):\n",
    "                start_idx = i * batch_size\n",
    "                end_idx = min((i+1) * batch_size, len(x_train))\n",
    "                batch_x = x_train_shuffled[start_idx:end_idx]\n",
    "                batch_y = y_train_shuffled[start_idx:end_idx]\n",
    "                sess.run(train_step, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "            if epoch % 10 == 0 or epoch == 1:\n",
    "                # 손실 및 정확도 계산\n",
    "                train_loss, train_acc = sess.run([loss, accuracy], feed_dict={x: x_train, y: y_train})\n",
    "                val_loss, val_acc = sess.run([loss, accuracy], feed_dict={x: x_val, y: y_val})\n",
    "                test_loss, test_acc = sess.run([loss, accuracy], feed_dict={x: x_test, y: y_test})\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                test_losses.append(test_loss)\n",
    "                train_accuracies.append(train_acc)\n",
    "                val_accuracies.append(val_acc)\n",
    "                test_accuracies.append(test_acc)\n",
    "                print(f'Epoch {epoch}, Training Loss: {train_loss:.4f}, Training Accuracy: {train_acc:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "        # 최종 예측 수행\n",
    "        predictions = sess.run(prediction, feed_dict={x: x_test})\n",
    "\n",
    "    return train_losses, val_losses, test_losses, train_accuracies, val_accuracies, test_accuracies, predictions\n",
    "\n",
    "# 모델 학습 및 결과 도출\n",
    "def learn(data, param_grid):\n",
    "    print('1. Training Models')\n",
    "\n",
    "    x_train = data[0]\n",
    "    best_report = None\n",
    "    best_test_accuracy = -1\n",
    "\n",
    "    # 하이퍼파라미터 조합 생성\n",
    "    keys = param_grid.keys()\n",
    "    combinations = list(itertools.product(*(param_grid[key] for key in keys)))\n",
    "\n",
    "    print(f\"Total parameter combinations: {len(combinations)}\")\n",
    "\n",
    "    for idx, combo in enumerate(combinations, 1):\n",
    "        params = dict(zip(keys, combo))\n",
    "        print(f\"Training model {idx}/{len(combinations)} with parameters:\")\n",
    "        print(f\"Hidden sizes: {params['hidden_sizes']}, Optimizer: {params['optimizer'].__name__}, Learning rate: {params['learning_rate']}, Batch size: {params['batch_size']}, Epochs: {params['epochs']}\")\n",
    "\n",
    "        optimizer_class = params['optimizer']\n",
    "        learning_rate = params['learning_rate']\n",
    "        hidden_sizes = params['hidden_sizes']\n",
    "        epochs = params['epochs']\n",
    "        batch_size = params['batch_size']\n",
    "\n",
    "        # 옵티마이저 인스턴스 생성\n",
    "        optimizer = optimizer_class(learning_rate=learning_rate)\n",
    "\n",
    "        # 모델 생성\n",
    "        x, y, prediction, loss, train_step, accuracy = create_model(optimizer, x_train.shape[1], hidden_sizes)\n",
    "\n",
    "        # 모델 실행 및 결과 수집\n",
    "        train_losses, val_losses, test_losses, train_accuracies, val_accuracies, test_accuracies, predictions = execute_model(\n",
    "            x, y, prediction, loss, train_step, accuracy, data, epochs, batch_size\n",
    "        )\n",
    "\n",
    "        # 결과 출력\n",
    "        print(f\"Optimizer: {optimizer_class.__name__}, Learning rate: {learning_rate}\")\n",
    "        print(f\"Hidden sizes: {hidden_sizes}, Batch size: {batch_size}, Epochs: {epochs}\")\n",
    "        print(f\"Training loss: {train_losses[-1]:.4f}\")\n",
    "        print(f\"Validation loss: {val_losses[-1]:.4f}\")\n",
    "        print(f\"Test loss: {test_losses[-1]:.4f}\")\n",
    "        print(f\"Test Accuracy: {test_accuracies[-1]:.4f}\\n\")\n",
    "\n",
    "        # 최고 성능 모델 업데이트 (테스트 정확도가 가장 높은 모델 선택)\n",
    "        if test_accuracies[-1] > best_test_accuracy:\n",
    "            best_test_accuracy = test_accuracies[-1]\n",
    "            best_report = {\n",
    "                \"params\": params,\n",
    "                \"train_losses\": train_losses,\n",
    "                \"val_losses\": val_losses,\n",
    "                \"test_losses\": test_losses,\n",
    "                \"train_accuracies\": train_accuracies,\n",
    "                \"val_accuracies\": val_accuracies,\n",
    "                \"test_accuracies\": test_accuracies,\n",
    "                \"predictions\": predictions,\n",
    "                \"y_test\": data[-1]\n",
    "            }\n",
    "            print(f\"New best model found: Test Accuracy = {best_test_accuracy:.4f}\\n\")\n",
    "\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "    return best_report\n",
    "\n",
    "########################\n",
    "# Report\n",
    "\n",
    "def generate_report(report):\n",
    "    print('2. Conclusion')\n",
    "    if report is None:\n",
    "        print(\"No report to generate.\")\n",
    "        return\n",
    "    params = report['params']\n",
    "    print(f\"Best Parameters:\")\n",
    "    print(f\"Optimizer: {params['optimizer'].__name__}\")\n",
    "    print(f\"Learning rate: {params['learning_rate']}\")\n",
    "    print(f\"Hidden sizes: {params['hidden_sizes']}\")\n",
    "    print(f\"Batch size: {params['batch_size']}\")\n",
    "    print(f\"Epochs: {params['epochs']}\")\n",
    "    print(f\"Training loss: {report['train_losses'][-1]:.4f}\")\n",
    "    print(f\"Validation loss: {report['val_losses'][-1]:.4f}\")\n",
    "    print(f\"Test loss: {report['test_losses'][-1]:.4f}\")\n",
    "    print(f\"Test Accuracy: {report['test_accuracies'][-1]:.4f}\")\n",
    "\n",
    "    # 실제 값과 예측 값 출력\n",
    "    y_test = report['y_test']\n",
    "    predictions = report['predictions']\n",
    "    print(\"\\nActual Values vs Predicted Values:\")\n",
    "    for actual, predicted in zip(y_test.argmax(axis=1), predictions.argmax(axis=1)):\n",
    "        print(f\"Actual: {actual}, Predicted: {predicted}\")\n",
    "\n",
    "########################\n",
    "# 파라미터 그리드 설정\n",
    "\n",
    "# 3(hidden_sizes) * 3(optimizer) * 3(learning_rate) * 3(batch_size) * 3(epochs) = 243 개의 모델을 생성\n",
    "param_grid = {\n",
    "    # 뉴런 수 (Ex. [32, 16, 8]로 설정하면 3개의 히든 레이어가 생성 되고 뉴런 수는 각각 32, 16, 8로 할당)\n",
    "    'hidden_sizes': [[32, 16, 8], [16, 16, 16], [8, 16, 32]],\n",
    "    # 옵티마이저 -\n",
    "    # tf.train.GradientDescentOptimizer, tf.train.AdamOptimizer, tf.train.AdagradOptimizer\n",
    "    'optimizer': [tf.train.GradientDescentOptimizer, tf.train.AdamOptimizer, tf.train.AdagradOptimizer],\n",
    "    # 학습률\n",
    "    'learning_rate': [0.01, 0.001, 0.0001],\n",
    "    # 배치 사이즈\n",
    "    'batch_size': [16, 32, 64],\n",
    "    # Epochs\n",
    "    'epochs': [100, 200, 300]\n",
    "}\n",
    "\n",
    "########################\n",
    "# 메인 실행 흐름\n",
    "\n",
    "def main():\n",
    "    # 데이터 로드 및 전처리\n",
    "    x_data, y_data = load_csv('fetal_health.csv')\n",
    "    x_train, x_val, x_test, y_train, y_val, y_test = split_data(x_data, y_data)\n",
    "    data = (x_train, x_val, x_test, y_train, y_val, y_test)\n",
    "\n",
    "    # Learning\n",
    "    best_report = learn(data, param_grid)\n",
    "\n",
    "    # Report\n",
    "    generate_report(best_report)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
